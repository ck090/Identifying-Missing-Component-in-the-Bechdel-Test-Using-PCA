{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A quick Gender Recognition model\n",
    "Grabbed from [nlpforhackers](https://nlpforhackers.io/introduction-machine-learning/) webpage.\n",
    "1. Firstly speaks about how to convert the dataset into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index       name sex\n",
      "0      0       Mary   F\n",
      "1      1       Anna   F\n",
      "2      2       Emma   F\n",
      "3      3  Elizabeth   F\n",
      "4      4     Minnie   F\n",
      "5      5   Margaret   F\n",
      "6      6        Ida   F\n",
      "7      7      Alice   F\n",
      "8      8     Bertha   F\n",
      "9      9      Sarah   F\n",
      "95025 names in dataset\n"
     ]
    }
   ],
   "source": [
    "names = pd.read_csv('names_dataset.csv')\n",
    "print names.head(10)\n",
    " \n",
    "print \"%d names in dataset\" % len(names) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Mary' 'F']\n",
      " ['Anna' 'F']\n",
      " ['Emma' 'F']\n",
      " ...\n",
      " ['Ziyu' 'M']\n",
      " ['Zykir' 'M']\n",
      " ['Zyus' 'M']]\n"
     ]
    }
   ],
   "source": [
    "# Get the data out of the dataframe into a numpy matrix and keep only the name and gender columns\n",
    "names = names.as_matrix()[:, 1:]\n",
    "print names\n",
    " \n",
    "# We're using 80% of the data for training\n",
    "TRAIN_SPLIT = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first2-letters': 'al', 'last-letter': 'x', 'first-letter': 'a', 'last2-letters': 'ex', 'last3-letters': 'lex', 'first3-letters': 'ale'}\n"
     ]
    }
   ],
   "source": [
    "def features(name):\n",
    "    name = name.lower()\n",
    "    return {\n",
    "        'first-letter': name[0], # First letter\n",
    "        'first2-letters': name[0:2], # First 2 letters\n",
    "        'first3-letters': name[0:3], # First 3 letters\n",
    "        'last-letter': name[-1],\n",
    "        'last2-letters': name[-2:],\n",
    "        'last3-letters': name[-3:],\n",
    "    }\n",
    "\n",
    "# Feature Extraction\n",
    "print features(\"Alex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'first2-letters': 'an', 'last-letter': 'a', 'first-letter': 'a', 'last2-letters': 'na', 'last3-letters': 'nna', 'first3-letters': 'ann'}\n",
      " {'first2-letters': 'ha', 'last-letter': 'h', 'first-letter': 'h', 'last2-letters': 'ah', 'last3-letters': 'nah', 'first3-letters': 'han'}\n",
      " {'first2-letters': 'pa', 'last-letter': 'l', 'first-letter': 'p', 'last2-letters': 'ul', 'last3-letters': 'aul', 'first3-letters': 'pau'}]\n",
      "Name: Mary, features={'first2-letters': 'ma', 'last-letter': 'y', 'first-letter': 'm', 'last2-letters': 'ry', 'last3-letters': 'ary', 'first3-letters': 'mar'}, gender=F\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the features function\n",
    "features = np.vectorize(features)\n",
    "print features([\"Anna\", \"Hannah\", \"Paul\"])\n",
    "# [ array({'first2-letters': 'an', 'last-letter': 'a', 'first-letter': 'a', 'last2-letters': 'na', 'last3-letters': 'nna', 'first3-letters': 'ann'}, dtype=object)\n",
    "#   array({'first2-letters': 'ha', 'last-letter': 'h', 'first-letter': 'h', 'last2-letters': 'ah', 'last3-letters': 'nah', 'first3-letters': 'han'}, dtype=object)\n",
    "#   array({'first2-letters': 'pa', 'last-letter': 'l', 'first-letter': 'p', 'last2-letters': 'ul', 'last3-letters': 'aul', 'first3-letters': 'pau'}, dtype=object)]\n",
    " \n",
    "# Extract the features for the whole dataset\n",
    "X = features(names[:, 0]) # X contains the features\n",
    " \n",
    "# Get the gender column\n",
    "y = names[:, 1]           # y contains the targets\n",
    " \n",
    "# Test if we built the dataset correctly\n",
    "print \"Name: %s, features=%s, gender=%s\" % (names[0][0], X[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76020 19005 76020 19005\n"
     ]
    }
   ],
   "source": [
    "X, y = shuffle(X, y)\n",
    "X_train, X_test = X[:int(TRAIN_SPLIT * len(X))], X[int(TRAIN_SPLIT * len(X)):]\n",
    "y_train, y_test = y[:int(TRAIN_SPLIT * len(y))], y[int(TRAIN_SPLIT * len(y)):]\n",
    "# Check to see if the datasets add up\n",
    "print len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'first2-letters': 'ma', 'last-letter': 'y', 'first-letter': 'm', 'last2-letters': 'ry', 'last3-letters': 'ary', 'first3-letters': 'mar'}\n",
      " {'first2-letters': 'jo', 'last-letter': 'n', 'first-letter': 'j', 'last2-letters': 'hn', 'last3-letters': 'ohn', 'first3-letters': 'joh'}]\n",
      "  (0, 12)\t1.0\n",
      "  (0, 242)\t1.0\n",
      "  (0, 2709)\t1.0\n",
      "  (0, 4478)\t1.0\n",
      "  (0, 4788)\t1.0\n",
      "  (0, 5115)\t1.0\n",
      "  (1, 9)\t1.0\n",
      "  (1, 197)\t1.0\n",
      "  (1, 2255)\t1.0\n",
      "  (1, 4467)\t1.0\n",
      "  (1, 4604)\t1.0\n",
      "  (1, 7152)\t1.0\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "1.0\n",
      "first-letter=m\n"
     ]
    }
   ],
   "source": [
    "print features([\"Mary\", \"John\"])\n",
    "vectorizer = DictVectorizer()\n",
    "vectorizer.fit(X_train)\n",
    "transformed = vectorizer.transform(features([\"Mary\", \"John\"]))\n",
    "print transformed\n",
    "\n",
    "print type(transformed) # <class 'scipy.sparse.csr.csr_matrix'>\n",
    "print transformed.toarray()[0][12]    # 1.0\n",
    "print vectorizer.feature_names_[12]   # first-letter=m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(vectorizer.transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.987687450670876\n",
      "0.869665877400684\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on training set\n",
    "print clf.score(vectorizer.transform(X_train), y_train) \n",
    " \n",
    "# Accuracy on test set\n",
    "print clf.score(vectorizer.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F']\n"
     ]
    }
   ],
   "source": [
    "print clf.predict(vectorizer.transform(features([\"CHASTITY\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
